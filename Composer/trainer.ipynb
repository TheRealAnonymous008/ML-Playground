{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import NoteComposeNet\n",
    "from dataset import MidiDataset, VOCABULARY\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'notes': [torch.tensor([1 for i in range(0, 255)])],\n",
    "    'velocities': [torch.tensor([1 for i in range(0, 255)])],\n",
    "    'durations': [torch.tensor([1 for i in range(0, 255)])],\n",
    "    'times': [torch.tensor([1 for i in range(0, 255)])],     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NoteComposeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 0.079MB\n"
     ]
    }
   ],
   "source": [
    "# Model Specifications\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m midi \u001b[39m=\u001b[39m MidiDataset(df, context_len \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_context_len)\n\u001b[0;32m      2\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(midi, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "midi = MidiDataset(df, context_len = model._context_len)\n",
    "train_loader = DataLoader(midi, batch_size=1)\n",
    "\n",
    "data = next(iter(train_loader))\n",
    "note_tensor = data['notes'].to(\"cuda\")\n",
    "velocity_tensor = data['velocities'].to(\"cuda\")\n",
    "duration_tensor = data['durations'].to(\"cuda\")\n",
    "time_tensor = data['times'].to(\"cuda\")\n",
    "\n",
    "input = {\n",
    "    \"notes\": note_tensor,\n",
    "    \"velocities\": velocity_tensor,\n",
    "    \"durations\": duration_tensor ,\n",
    "    \"times\": time_tensor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joaquin\\Desktop\\Playground\\ML\\Composer\\model.py:114: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  def detokenize(self, inputs):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note =  ['A♯-1', 'D♯8', '<EOS>', 'D♯5', 'A1', 'E9', 'A♯0', 'D♯8', 'B2', 'E1', 'A6', 'C♯5', 'G♯3', 'F9', 'C5', 'A6', 'C9', 'B3', 'E1', 'C1', 'C9', 'F5', 'E1', 'A6', 'C9', 'D♯5', 'A1', 'E1', 'D♯5', 'D♯8', 'D♯8', 'B7', 'C♯0', 'F♯9', 'B7', 'F♯1', 'F2', 'D♯5', 'C♯2', 'D7', 'G2', 'A♯0', 'C♯5', 'G5', 'F0', 'D1', 'G♯0', 'E1', 'G♯3', 'E1', 'A1', 'C7', 'F0', 'G0', 'C5', 'F5', 'B3', 'F5', 'E1', 'G2', 'G3', 'A6', 'F2', 'F0', 'B0', 'A6', 'C♯5', 'F♯6', 'C♯2', 'E1', 'A6', 'A1', 'A6', 'A1', 'A6', 'F5', 'G0', 'C5', 'G0', 'A6', 'F5', 'B3', 'D♯-1', 'A6', 'C♯5', 'B3', 'E3', 'A6', 'G0', 'A♯-1', 'F0', 'E0', 'B2', 'E1', 'D2', 'C♯5', 'C♯-1', 'F5', 'E1', 'A6']\n"
     ]
    }
   ],
   "source": [
    "test_inputs = np.random.randint(0, len(VOCABULARY), size=255, dtype=int)\n",
    "next_notes = model.generate(test_inputs, max_len=100)\n",
    "print(\"Note = \", model.detokenize(next_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import NoteComposeNet\n",
    "from dataset import MidiDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NoteComposeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=0.001, \n",
    "    weight_decay=0.004,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-07, \n",
    "    amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = r'midi-dataset-mini.csv'\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "midi = MidiDataset(df, context_len = model._context_len)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    midi, \n",
    "    batch_size=3,\n",
    "    num_workers=1,\n",
    "    shuffle=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch(batch):\n",
    "    b, attn, gt = batch\n",
    "    \n",
    "    notes = b['notes'].to(model._device)\n",
    "    notes_gt = gt['notes'].to(model._device)\n",
    "\n",
    "    output_logits = model.forward(notes)\n",
    "\n",
    "    return output_logits, notes_gt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0229e-32, 2.8665e-32, 2.3394e-32, 1.8517e-32, 1.3781e-32, 2.9592e-32,\n",
      "        1.4465e-32, 2.0021e-32, 4.4173e-32, 2.4039e-32, 2.4819e-32, 1.2922e-32,\n",
      "        3.7706e-32, 1.1136e-32, 2.9599e-32, 2.6426e-32, 3.7953e-32, 2.3808e-32,\n",
      "        9.8274e-33, 3.3968e-32, 2.4353e-32, 1.1287e-32, 2.2586e-32, 8.3622e-33,\n",
      "        1.0417e-32, 2.3354e-32, 1.7328e-32, 4.7355e-32, 5.3448e-32, 2.7813e-32,\n",
      "        9.7023e-33, 3.6294e-32, 1.8851e-32, 3.2778e-32, 4.3769e-32, 5.6649e-32,\n",
      "        2.6334e-32, 2.0862e-32, 2.4723e-32, 3.8891e-32, 2.8853e-32, 1.2458e-32,\n",
      "        2.2081e-32, 3.3754e-32, 9.7927e-33, 8.5685e-33, 3.1325e-32, 3.9987e-32,\n",
      "        5.5781e-32, 1.8470e-32, 1.8923e-32, 4.3796e-32, 2.3029e-32, 1.7737e-32,\n",
      "        1.3473e-32, 6.0103e-32, 3.1800e-32, 8.2457e-33, 3.4879e-32, 5.1131e-32,\n",
      "        1.6355e-32, 2.3355e-32, 1.6317e-32, 1.0608e-30, 1.4061e-32, 2.1613e-32,\n",
      "        2.7231e-32, 4.2099e-32, 2.3400e-32, 1.6047e-32, 1.3757e-32, 9.3226e-33,\n",
      "        2.2264e-32, 1.9266e-32, 3.1340e-32, 4.4527e-32, 2.2527e-32, 5.4373e-32,\n",
      "        1.6869e-32, 1.1753e-32, 1.7276e-32, 1.6896e-32, 1.3080e-32, 1.2137e-32,\n",
      "        2.7224e-32, 2.2159e-32, 3.8082e-32, 2.8382e-32, 3.0951e-32, 2.8586e-32,\n",
      "        1.6072e-32, 3.1095e-32, 2.3420e-32, 9.4450e-33, 2.4101e-32, 9.5344e-33,\n",
      "        1.1508e-32, 2.8853e-32, 2.9570e-32, 1.3437e-32, 2.4366e-32, 3.1700e-32,\n",
      "        1.7353e-32, 2.3039e-32, 2.8968e-32, 1.2020e-32, 3.0037e-32, 1.3258e-32,\n",
      "        1.1395e-32, 2.2303e-32, 1.7327e-32, 1.1356e-32, 2.3252e-32, 2.1744e-32,\n",
      "        3.4358e-32, 1.0674e-32, 4.2641e-31, 1.5889e-32, 8.1734e-30, 1.6576e-32,\n",
      "        3.1393e-32, 1.0773e-32, 2.5646e-32, 2.0550e-32, 1.2836e-31, 1.5499e-32,\n",
      "        1.4486e-32, 2.2255e-32, 8.1548e-32, 1.6015e-32, 1.0000e+00, 2.0252e-32],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0.], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    output_logits, notes_gt = unpack_batch(batch)\n",
    "\n",
    "    loss = loss_fn(output_logits, notes_gt)\n",
    "\n",
    "    print(output_logits[0])\n",
    "    print(notes_gt[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output_logits, notes_gt = unpack_batch(batch)\n",
    "        \n",
    "        loss = loss_fn(output_logits, notes_gt)\n",
    "        loss.backward() \n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.0 valid 3.895735263824463\n",
      "EPOCH 2:\n",
      "LOSS train 0.0 valid 3.895735263824463\n",
      "EPOCH 3:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model\u001b[39m.\u001b[39mtrain(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m avg_loss \u001b[39m=\u001b[39m train_one_epoch(epoch_number, writer)\n\u001b[0;32m     18\u001b[0m running_vloss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m# statistics for batch normalization.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch_index, tb_writer)\u001b[0m\n\u001b[0;32m      2\u001b[0m running_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[0;32m      3\u001b[0m last_loss \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      8\u001b[0m     output_logits, notes_gt \u001b[39m=\u001b[39m unpack_batch(batch)\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:629\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 629\u001b[0m     \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_profile_name):\n\u001b[0;32m    630\u001b[0m         \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sampler_iter \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m:\n\u001b[0;32m    631\u001b[0m             \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;49;00m\n\u001b[0;32m    632\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\torch\\autograd\\profiler.py:492\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 492\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n\u001b[0;32m    493\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Joaquin\\miniconda3\\envs\\agienv\\Lib\\site-packages\\torch\\_ops.py:502\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n\u001b[0;32m    500\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[0;32m    501\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_op(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs \u001b[39mor\u001b[39;49;00m {})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/composer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(train_loader):\n",
    "            voutputs, vgt = unpack_batch(vdata)\n",
    "            vloss = loss_fn(voutputs, vgt)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
