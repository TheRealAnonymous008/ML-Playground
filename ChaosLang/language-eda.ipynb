{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"./langdata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pronunciation(row, lang):\n",
    "    pronunciations = row[\"pronunciation\"].split(',')\n",
    "    return pd.DataFrame({\"pronunciation\": pronunciations, \n",
    "                         \"word\": [row[\"word\"]] * len(pronunciations), \n",
    "                         \"language\": [lang] * len(pronunciations)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Persian\n",
      "71 Polish\n",
      "72 Portuguese\n",
      "73 Punjabi\n",
      "74 Quechua\n",
      "75 Romanian\n",
      "76 Russian\n",
      "77 Samoan\n",
      "78 Scottish_Gaelic\n",
      "79 Serbo-Croatian\n",
      "80 Shona\n",
      "81 Sinhalese\n",
      "82 Slovak\n",
      "83 Slovene\n",
      "84 Somali\n",
      "85 Sotho\n",
      "86 Spanish\n",
      "87 Swahili\n",
      "88 Swedish\n",
      "89 Tagalog\n",
      "90 Tajik\n",
      "91 Tamil\n",
      "92 Tatar\n",
      "93 Telugu\n",
      "94 Thai\n",
      "95 Tibetan\n",
      "96 Tongan\n",
      "97 Tswana\n",
      "98 Turkish\n",
      "99 Turkmen\n",
      "100 Ukrainian\n",
      "101 Urdu\n",
      "102 Uyghur\n",
      "103 Uzbek\n",
      "104 Vietnamese\n",
      "105 Welsh\n",
      "106 Wolof\n",
      "107 Xhosa\n",
      "108 Yiddish\n",
      "109 Yoruba\n",
      "110 Zulu\n"
     ]
    }
   ],
   "source": [
    "loaded_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "ctr = 0\n",
    "lang_ctr = 7\n",
    "\n",
    "start_idx = lang_ctr * 10 + ctr \n",
    "for lang in LANGUAGES[start_idx:]:\n",
    "    ctr += 1\n",
    "    print(lang_ctr * 10 + ctr - 1, lang)\n",
    "\n",
    "    df = pd.read_csv(FILE_DIR + lang + \".csv\")\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "        P = split_pronunciation(x, lang)\n",
    "        loaded_df  = pd.concat([loaded_df, P], ignore_index=True)\n",
    "\n",
    "        del P \n",
    "    \n",
    "    if ctr == 10: \n",
    "        loaded_df.to_csv(f\"full_dataset_v0_{lang_ctr}.csv\")\n",
    "        loaded_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "        lang_ctr += 1\n",
    "        ctr = 0\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "# Merge all entries \n",
    "for i in range(0, 12):\n",
    "    file = f\"dataset/full_dataset_v0_{i}.csv\"\n",
    "    df = pd.read_csv(file)\n",
    "    merged_df = pd.concat([merged_df, df[[\"pronunciation\", \"word\", \"language\"]]], ignore_index=True)\n",
    "\n",
    "    del df \n",
    "\n",
    "merged_df.to_csv(\"full_dataset_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['pronunciation'].str.len().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of pronunciations\n",
    "pronunciation_list = []\n",
    "for p in loaded_df['pronunciation']:\n",
    "    _pronunciations = p.split(',')\n",
    "    pronunciation_list.extend(_pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the different symbols\n",
    "symbols_hist = {}\n",
    "\n",
    "for P in pronunciation_list:\n",
    "    # Make use of only the narrow transcriptions.\n",
    "    for x in P:\n",
    "        if x in symbols_hist.keys():\n",
    "            symbols_hist[x] += 1\n",
    "        else:\n",
    "            symbols_hist[x] = 1  \n",
    "\n",
    "# Sort the symbols \n",
    "symbols = sorted(symbols_hist, key = lambda x: symbols_hist[x], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ 4476098\n",
      ". 2668759\n",
      "ˈ 2586695\n",
      "t 2229753\n",
      "a 2224633\n",
      "i 2190798\n",
      "s 1803318\n",
      "[ 1589385\n",
      "] 1589372\n",
      "n 1530543\n",
      "k 1366328\n",
      "e 1337835\n",
      "o 1125199\n",
      "ː 1079266\n",
      "l 1057976\n",
      "u 1036695\n",
      "m 951127\n",
      "r 882474\n",
      "p 837609\n",
      "  813632\n",
      "ə 796376\n",
      "d 785937\n",
      "ɪ 741169\n",
      "ʲ 739525\n",
      "ɛ 698681\n",
      "j 689633\n",
      "͡ 633477\n",
      "ɑ 620842\n",
      "⁵ 615160\n",
      "ɔ 565528\n",
      "ɐ 551614\n",
      "̯ 506961\n",
      "b 488955\n",
      "² 472052\n",
      "ɾ 468753\n",
      "³ 449769\n",
      "¹ 432997\n",
      "v 430650\n",
      "ˌ 410958\n",
      "̞ 396212\n",
      "̪ 394208\n",
      "ʁ 388090\n",
      "ɡ 351288\n",
      "z 350069\n",
      "⁴ 349785\n",
      "f 340051\n",
      "ʃ 328965\n",
      "ʊ 309841\n",
      "ŋ 283073\n",
      "⁻ 270178\n",
      "̃ 260185\n",
      "ʰ 258645\n",
      "ɨ 253132\n",
      "ɕ 249545\n",
      "̠ 223479\n",
      "w 200159\n",
      "h 198001\n",
      "̝ 193594\n",
      ") 184662\n",
      "( 184659\n",
      "ä 159839\n",
      "y 159126\n",
      "ʂ 156036\n",
      "˧ 153971\n",
      "ʒ 153157\n",
      "æ 149212\n",
      "x 142695\n",
      "ɫ 138785\n",
      "̚ 136744\n",
      "ʔ 134557\n",
      "ʋ 124771\n",
      "˨ 84160\n",
      "˩ 83217\n",
      "ɲ 82881\n",
      "ð 76842\n",
      "̟ 67262\n",
      "˦ 66020\n",
      "ẽ 62046\n",
      "ʐ 61316\n",
      "ɒ 58223\n",
      "ɹ 56970\n",
      "θ 51376\n",
      "̩ 48095\n",
      "ø 45332\n",
      "ĩ 44738\n",
      "˥ 44108\n",
      "ʈ 41794\n",
      "ɦ 41516\n",
      "ɣ 36789\n",
      "ɯ 36788\n",
      "⁽ 35285\n",
      "⁾ 35285\n",
      "ᵝ 34931\n",
      "β 34388\n",
      "ɤ 32685\n",
      "õ 31560\n",
      "ã 30361\n",
      "ˣ 26879\n",
      "ʎ 26520\n",
      "ʌ 25398\n",
      "ɵ 25132\n",
      "χ 24434\n",
      "ˠ 22455\n",
      "ʑ 21496\n",
      "ʝ 21244\n",
      "œ 19452\n",
      "ɻ 19385\n",
      "ç 16758\n",
      "c 15889\n",
      "̥ 15660\n",
      "ˀ 14055\n",
      "~ 13113\n",
      "ʏ 12944\n",
      "ʷ 12885\n",
      "‿ 12783\n",
      "ʉ 12692\n",
      "ʼ 12058\n",
      "̻ 11544\n",
      "ɥ 11347\n",
      "- 10895\n",
      "ũ 10715\n",
      "̹ 10711\n",
      "ɗ 10316\n",
      "ɓ 10096\n",
      "ɴ 9899\n",
      "ɟ 9763\n",
      "́ 9698\n",
      "ʱ 9533\n",
      "ǎ 9430\n",
      "ˑ 8206\n",
      "í 7882\n",
      "͈ 7799\n",
      "ɭ 7571\n",
      "à 7253\n",
      "ǒ 7251\n",
      "q 6750\n",
      "á 6684\n",
      "ɚ 6672\n",
      "ǐ 6656\n",
      "̺ 6529\n",
      "ě 6426\n",
      "̊ 6349\n",
      "ˤ 5531\n",
      "ǽ 5514\n",
      "̀ 5095\n",
      "ɖ 4942\n",
      "̍ 4758\n",
      "ɰ 4726\n",
      "â 4178\n",
      "ɳ 4036\n",
      "ɽ 4014\n",
      "ħ 3855\n",
      "ɜ 3714\n",
      "ê 3540\n",
      "ɸ 3532\n",
      "ú 3379\n",
      "ǔ 3199\n",
      "ì 3195\n",
      "é 2972\n",
      "ɱ 2883\n",
      "ɬ 2802\n",
      "̬ 2759\n",
      "ô 2690\n",
      "* 2670\n",
      "î 2568\n",
      "ó 2409\n",
      "ʀ 2246\n",
      "ʕ 2041\n",
      "ɝ 2032\n",
      "û 1949\n",
      "è 1854\n",
      "ò 1765\n",
      "̄ 1654\n",
      "ï 1636\n",
      "ɘ 1541\n",
      "̰ 1476\n",
      "ɮ 1465\n",
      "ù 1371\n",
      "→ 1309\n",
      "ā 1172\n",
      "ᵊ 1148\n",
      "ˢ 1055\n",
      "̂ 760\n",
      "̆ 749\n",
      "ō 739\n",
      "| 697\n",
      "ᵑ 694\n",
      "ř 660\n",
      "̤ 606\n",
      "ⁿ 588\n",
      "ī 579\n",
      "ɢ 550\n",
      "ᵐ 529\n",
      "  515\n",
      "g 513\n",
      "̜ 494\n",
      "ʍ 459\n",
      "ē 400\n",
      "̙ 395\n",
      "ɧ 352\n",
      "ǃ 333\n",
      "ᵘ 329\n",
      "ˡ 321\n",
      "ḭ 313\n",
      "ṵ 297\n",
      "̈ 259\n",
      "ū 256\n",
      "ɠ 251\n",
      "ṹ 249\n",
      "ȵ 240\n",
      "ḿ 223\n",
      "ǀ 202\n",
      "ꜜ 192\n",
      "ɶ 189\n",
      "ɞ 174\n",
      "͜ 148\n",
      "̽ 141\n",
      "ǁ 132\n",
      "∅ 115\n",
      "ḛ 110\n",
      "̌ 85\n",
      "ṳ 75\n",
      "⁰ 63\n",
      "ỹ 57\n",
      "ạ 57\n",
      "ᶯ 56\n",
      "ᶢ 52\n",
      "  49\n",
      "˕ 45\n",
      "ŏ 41\n",
      "᷈ 39\n",
      "͉ 37\n",
      "˞ 35\n",
      "' 34\n",
      "> 30\n",
      "˔ 28\n",
      "ë 28\n",
      "ǣ 28\n",
      "ḁ 27\n",
      "ă 26\n",
      "N 21\n",
      "ᶬ 19\n",
      "ᶮ 19\n",
      "‖ 18\n",
      "˗ 17\n",
      "ü 16\n",
      "… 16\n",
      "ŭ 15\n",
      "̘ 14\n",
      "ĕ 14\n",
      "◌ 12\n",
      "˖ 11\n",
      "C 11\n",
      "︎ 10\n",
      "↗ 9\n",
      "‌ 8\n",
      "͎ 8\n",
      "ᵏ 8\n",
      "ö 7\n",
      "ʙ 7\n",
      "ĭ 7\n",
      "å 7\n",
      "𝆑 7\n",
      "ʴ 6\n",
      "ŷ 6\n",
      "一 6\n",
      "ń 6\n",
      "ᴜ 6\n",
      "​ 5\n",
      "Q 5\n",
      "ý 5\n",
      "ŕ 4\n",
      "V 4\n",
      "ʟ 4\n",
      "ᵈ 4\n",
      "̣ 4\n",
      "͍ 4\n",
      "ñ 4\n",
      "ʳ 4\n",
      "ǹ 4\n",
      "၊ 3\n",
      "͇ 3\n",
      "↘ 3\n",
      "ᶣ 2\n",
      "ာ 2\n",
      "ေ 2\n",
      "် 2\n",
      "1 2\n",
      "↓ 2\n",
      "ʘ 2\n",
      "ᵻ 2\n",
      "ʄ 2\n",
      "ỳ 2\n",
      "̋ 2\n",
      "ẹ 2\n",
      "ň 2\n",
      "ʜ 1\n",
      "ᵇ 1\n",
      "᪽ 1\n",
      "ရ 1\n",
      "ခ 1\n",
      "ျ 1\n",
      "င 1\n",
      "; 1\n",
      "ဘ 1\n",
      "း 1\n",
      "+ 1\n",
      "’ 1\n",
      "မ 1\n",
      "ပ 1\n",
      "က 1\n",
      "⁓ 1\n",
      "⁹ 1\n",
      "ẑ 1\n",
      "& 1\n",
      "不 1\n",
      "ʬ 1\n",
      "ʩ 1\n",
      "𐞪 1\n",
      "ṽ 1\n",
      "꜔ 1\n",
      "% 1\n",
      "᷇ 1\n",
      "ɺ 1\n",
      "᷆ 1\n",
      "ȁ 1\n",
      "͏ 1\n",
      "ÿ 1\n",
      "ˇ 1\n",
      "ọ 1\n",
      "ỵ 1\n",
      "ᵄ 1\n",
      "ǿ 1\n",
      ": 1\n"
     ]
    }
   ],
   "source": [
    "for x in symbols:\n",
    "    print(x, symbols_hist[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "ˈ\n",
      "t\n",
      "a\n",
      "i\n",
      "s\n",
      "n\n",
      "k\n",
      "e\n",
      "o\n",
      "ː\n",
      "l\n",
      "u\n",
      "m\n",
      "r\n",
      "p\n",
      " \n",
      "ə\n",
      "d\n",
      "ɪ\n",
      "ʲ\n",
      "ɛ\n",
      "j\n",
      "͡\n",
      "ɑ\n",
      "⁵\n",
      "ɔ\n",
      "ɐ\n",
      "̯\n",
      "b\n",
      "²\n",
      "ɾ\n",
      "³\n",
      "¹\n",
      "v\n",
      "ˌ\n",
      "̞\n",
      "̪\n",
      "ʁ\n",
      "ɡ\n",
      "z\n",
      "⁴\n",
      "f\n",
      "ʃ\n",
      "ʊ\n",
      "ŋ\n",
      "⁻\n",
      "̃\n",
      "ʰ\n",
      "ɨ\n",
      "ɕ\n",
      "̠\n",
      "w\n",
      "h\n",
      "̝\n",
      ")\n",
      "(\n",
      "ä\n",
      "y\n",
      "ʂ\n",
      "˧\n",
      "ʒ\n",
      "æ\n",
      "x\n",
      "ɫ\n",
      "̚\n",
      "ʔ\n",
      "ʋ\n",
      "˨\n",
      "˩\n",
      "ɲ\n",
      "ð\n",
      "̟\n",
      "˦\n",
      "ẽ\n",
      "ʐ\n",
      "ɒ\n",
      "ɹ\n",
      "θ\n",
      "̩\n",
      "ø\n",
      "ĩ\n",
      "˥\n",
      "ʈ\n",
      "ɦ\n",
      "ɣ\n",
      "ɯ\n",
      "⁽\n",
      "⁾\n",
      "ᵝ\n",
      "β\n",
      "ɤ\n",
      "õ\n",
      "ã\n",
      "ˣ\n",
      "ʎ\n",
      "ʌ\n",
      "ɵ\n",
      "χ\n",
      "ˠ\n",
      "ʑ\n",
      "ʝ\n",
      "œ\n",
      "ɻ\n",
      "ç\n",
      "c\n",
      "̥\n",
      "ˀ\n",
      "~\n",
      "ʏ\n",
      "ʷ\n",
      "‿\n",
      "ʉ\n",
      "ʼ\n",
      "̻\n",
      "ɥ\n",
      "-\n",
      "ũ\n",
      "̹\n",
      "ɗ\n",
      "ɓ\n",
      "ɴ\n",
      "ɟ\n",
      "́\n",
      "ʱ\n",
      "ǎ\n",
      "ˑ\n",
      "í\n",
      "͈\n",
      "ɭ\n",
      "à\n",
      "ǒ\n",
      "q\n",
      "á\n",
      "ɚ\n",
      "ǐ\n",
      "̺\n",
      "ě\n",
      "̊\n",
      "ˤ\n",
      "ǽ\n",
      "̀\n",
      "ɖ\n",
      "̍\n",
      "ɰ\n",
      "â\n",
      "ɳ\n",
      "ɽ\n",
      "ħ\n",
      "ɜ\n",
      "ê\n",
      "ɸ\n",
      "ú\n",
      "ǔ\n",
      "ì\n",
      "é\n",
      "ɱ\n",
      "ɬ\n",
      "̬\n",
      "ô\n",
      "*\n",
      "î\n",
      "ó\n",
      "ʀ\n",
      "ʕ\n",
      "ɝ\n",
      "û\n",
      "è\n",
      "ò\n",
      "̄\n",
      "ï\n",
      "ɘ\n",
      "̰\n",
      "ɮ\n",
      "ù\n",
      "→\n",
      "ā\n",
      "ᵊ\n",
      "ˢ\n",
      "̂\n",
      "̆\n",
      "ō\n",
      "|\n",
      "ᵑ\n",
      "ř\n",
      "̤\n",
      "ⁿ\n",
      "ī\n",
      "ɢ\n",
      "ᵐ\n",
      " \n",
      "g\n",
      "̜\n",
      "ʍ\n",
      "ē\n",
      "̙\n",
      "ɧ\n",
      "ǃ\n",
      "ᵘ\n",
      "ˡ\n",
      "ḭ\n",
      "ṵ\n",
      "̈\n",
      "ū\n",
      "ɠ\n",
      "ṹ\n",
      "ȵ\n",
      "ḿ\n",
      "ǀ\n",
      "ꜜ\n",
      "ɶ\n",
      "ɞ\n",
      "͜\n",
      "̽\n",
      "ǁ\n",
      "∅\n",
      "ḛ\n",
      "̌\n",
      "ṳ\n",
      "⁰\n",
      "ỹ\n",
      "ạ\n",
      "ᶯ\n",
      "ᶢ\n",
      " \n",
      "˕\n",
      "ŏ\n",
      "᷈\n",
      "͉\n",
      "˞\n",
      "'\n",
      ">\n",
      "˔\n",
      "ë\n",
      "ǣ\n",
      "ḁ\n",
      "ă\n",
      "N\n",
      "ᶬ\n",
      "ᶮ\n",
      "‖\n",
      "˗\n",
      "ü\n",
      "…\n",
      "ŭ\n",
      "̘\n",
      "ĕ\n",
      "◌\n",
      "˖\n",
      "C\n",
      "︎\n",
      "↗\n",
      "‌\n",
      "͎\n",
      "ᵏ\n",
      "ö\n",
      "ʙ\n",
      "ĭ\n",
      "å\n",
      "𝆑\n",
      "ʴ\n",
      "ŷ\n",
      "一\n",
      "ń\n",
      "ᴜ\n",
      "​\n",
      "Q\n",
      "ý\n",
      "ŕ\n",
      "V\n",
      "ʟ\n",
      "ᵈ\n",
      "̣\n",
      "͍\n",
      "ñ\n",
      "ʳ\n",
      "ǹ\n",
      "၊\n",
      "͇\n",
      "↘\n",
      "ᶣ\n",
      "ာ\n",
      "ေ\n",
      "်\n",
      "1\n",
      "↓\n",
      "ʘ\n",
      "ᵻ\n",
      "ʄ\n",
      "ỳ\n",
      "̋\n",
      "ẹ\n",
      "ň\n",
      "ʜ\n",
      "ᵇ\n",
      "᪽\n",
      "ရ\n",
      "ခ\n",
      "ျ\n",
      "င\n",
      ";\n",
      "ဘ\n",
      "း\n",
      "+\n",
      "’\n",
      "မ\n",
      "ပ\n",
      "က\n",
      "⁓\n",
      "⁹\n",
      "ẑ\n",
      "&\n",
      "不\n",
      "ʬ\n",
      "ʩ\n",
      "𐞪\n",
      "ṽ\n",
      "꜔\n",
      "%\n",
      "᷇\n",
      "ɺ\n",
      "᷆\n",
      "ȁ\n",
      "͏\n",
      "ÿ\n",
      "ˇ\n",
      "ọ\n",
      "ỵ\n",
      "ᵄ\n",
      "ǿ\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "for s in symbols:\n",
    "    if s == \"/\" or s == \"[\" or s == \"]\":\n",
    "        continue \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>word</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/ʐ/</td>\n",
       "      <td>ƶ</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/aapa/</td>\n",
       "      <td>ааба</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[ʔäˑˈbɜ]</td>\n",
       "      <td>ааба</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[ābʁʲa]</td>\n",
       "      <td>аабӷьа</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[aːdzara]</td>\n",
       "      <td>ааӡара</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 pronunciation    word language\n",
       "0           0           /ʐ/       ƶ   Abkhaz\n",
       "1           1        /aapa/    ааба   Abkhaz\n",
       "2           2      [ʔäˑˈbɜ]    ааба   Abkhaz\n",
       "3           3       [ābʁʲa]  аабӷьа   Abkhaz\n",
       "4           4     [aːdzara]  ааӡара   Abkhaz"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df = pd.read_csv(\"full_dataset_v0.csv\")\n",
    "symbols = np.load(\"symbols.npy\")\n",
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, symbol_list):\n",
    "        super().__init__(max_len=512)  # You can adjust max_len based on your needs\n",
    "        self.vocabulary = {\n",
    "            \"[PAD]\": 0,\n",
    "            \"[CLS]\": 1,\n",
    "            \"[SEP]\": 2,\n",
    "            \"[MASK]\": 3,\n",
    "            \"[UNK]\": 4,\n",
    "        }\n",
    "        for symbol in symbol_list:\n",
    "            self.vocabulary[symbol] = len(self.vocabulary)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        tokens = []\n",
    "        for char in text:\n",
    "            tokens.append(char)\n",
    "        return tokens\n",
    "    \n",
    "    def convert_tokens_to_ids(self, x):\n",
    "        tokens = self._tokenize(x)\n",
    "        return [self._convert_token_to_id(token) for token in tokens]\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        return self.vocabulary.get(token, self.vocabulary[\"[UNK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = LANGUAGES\n",
    "\n",
    "    def tokenize(self, x):\n",
    "        return self.vocabulary.index(x) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation_tokenizer = CustomTokenizer(symbols)\n",
    "language_tokenizer = LanguageTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5, 83, 5], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(loaded_df)):\n",
    "    x = loaded_df.iloc[i]\n",
    "    pronunciations = pronunciation_tokenizer(x[\"pronunciation\"])\n",
    "    languages = language_tokenizer.tokenize(x[\"language\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
