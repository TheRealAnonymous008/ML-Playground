{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = \"./langdata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pronunciation(row, lang):\n",
    "    pronunciations = row[\"pronunciation\"].split(',')\n",
    "    return pd.DataFrame({\"pronunciation\": pronunciations, \n",
    "                         \"word\": [row[\"word\"]] * len(pronunciations), \n",
    "                         \"language\": [lang] * len(pronunciations)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 Persian\n",
      "71 Polish\n",
      "72 Portuguese\n",
      "73 Punjabi\n",
      "74 Quechua\n",
      "75 Romanian\n",
      "76 Russian\n",
      "77 Samoan\n",
      "78 Scottish_Gaelic\n",
      "79 Serbo-Croatian\n",
      "80 Shona\n",
      "81 Sinhalese\n",
      "82 Slovak\n",
      "83 Slovene\n",
      "84 Somali\n",
      "85 Sotho\n",
      "86 Spanish\n",
      "87 Swahili\n",
      "88 Swedish\n",
      "89 Tagalog\n",
      "90 Tajik\n",
      "91 Tamil\n",
      "92 Tatar\n",
      "93 Telugu\n",
      "94 Thai\n",
      "95 Tibetan\n",
      "96 Tongan\n",
      "97 Tswana\n",
      "98 Turkish\n",
      "99 Turkmen\n",
      "100 Ukrainian\n",
      "101 Urdu\n",
      "102 Uyghur\n",
      "103 Uzbek\n",
      "104 Vietnamese\n",
      "105 Welsh\n",
      "106 Wolof\n",
      "107 Xhosa\n",
      "108 Yiddish\n",
      "109 Yoruba\n",
      "110 Zulu\n"
     ]
    }
   ],
   "source": [
    "loaded_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "ctr = 0\n",
    "lang_ctr = 7\n",
    "\n",
    "start_idx = lang_ctr * 10 + ctr \n",
    "for lang in LANGUAGES[start_idx:]:\n",
    "    ctr += 1\n",
    "    print(lang_ctr * 10 + ctr - 1, lang)\n",
    "\n",
    "    df = pd.read_csv(FILE_DIR + lang + \".csv\")\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "        P = split_pronunciation(x, lang)\n",
    "        loaded_df  = pd.concat([loaded_df, P], ignore_index=True)\n",
    "\n",
    "        del P \n",
    "    \n",
    "    if ctr == 10: \n",
    "        loaded_df.to_csv(f\"full_dataset_v0_{lang_ctr}.csv\")\n",
    "        loaded_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "        lang_ctr += 1\n",
    "        ctr = 0\n",
    "    del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame({\"pronunciation\": [], \"word\": [], \"language\": []}) \n",
    "# Merge all entries \n",
    "for i in range(0, 12):\n",
    "    file = f\"dataset/full_dataset_v0_{i}.csv\"\n",
    "    df = pd.read_csv(file)\n",
    "    merged_df = pd.concat([merged_df, df[[\"pronunciation\", \"word\", \"language\"]]], ignore_index=True)\n",
    "\n",
    "    del df \n",
    "\n",
    "merged_df.to_csv(\"full_dataset_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['pronunciation'].str.len().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the list of pronunciations\n",
    "pronunciation_list = []\n",
    "for p in loaded_df['pronunciation']:\n",
    "    _pronunciations = p.split(',')\n",
    "    pronunciation_list.extend(_pronunciations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a histogram of the different symbols\n",
    "symbols_hist = {}\n",
    "\n",
    "for P in pronunciation_list:\n",
    "    # Make use of only the narrow transcriptions.\n",
    "    for x in P:\n",
    "        if x in symbols_hist.keys():\n",
    "            symbols_hist[x] += 1\n",
    "        else:\n",
    "            symbols_hist[x] = 1  \n",
    "\n",
    "# Sort the symbols \n",
    "symbols = sorted(symbols_hist, key = lambda x: symbols_hist[x], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ 4476098\n",
      ". 2668759\n",
      "Àà 2586695\n",
      "t 2229753\n",
      "a 2224633\n",
      "i 2190798\n",
      "s 1803318\n",
      "[ 1589385\n",
      "] 1589372\n",
      "n 1530543\n",
      "k 1366328\n",
      "e 1337835\n",
      "o 1125199\n",
      "Àê 1079266\n",
      "l 1057976\n",
      "u 1036695\n",
      "m 951127\n",
      "r 882474\n",
      "p 837609\n",
      "  813632\n",
      "…ô 796376\n",
      "d 785937\n",
      "…™ 741169\n",
      " ≤ 739525\n",
      "…õ 698681\n",
      "j 689633\n",
      "Õ° 633477\n",
      "…ë 620842\n",
      "‚Åµ 615160\n",
      "…î 565528\n",
      "…ê 551614\n",
      "ÃØ 506961\n",
      "b 488955\n",
      "¬≤ 472052\n",
      "…æ 468753\n",
      "¬≥ 449769\n",
      "¬π 432997\n",
      "v 430650\n",
      "Àå 410958\n",
      "Ãû 396212\n",
      "Ã™ 394208\n",
      " Å 388090\n",
      "…° 351288\n",
      "z 350069\n",
      "‚Å¥ 349785\n",
      "f 340051\n",
      " É 328965\n",
      " ä 309841\n",
      "≈ã 283073\n",
      "‚Åª 270178\n",
      "ÃÉ 260185\n",
      " ∞ 258645\n",
      "…® 253132\n",
      "…ï 249545\n",
      "Ã† 223479\n",
      "w 200159\n",
      "h 198001\n",
      "Ãù 193594\n",
      ") 184662\n",
      "( 184659\n",
      "√§ 159839\n",
      "y 159126\n",
      " Ç 156036\n",
      "Àß 153971\n",
      " í 153157\n",
      "√¶ 149212\n",
      "x 142695\n",
      "…´ 138785\n",
      "Ãö 136744\n",
      " î 134557\n",
      " ã 124771\n",
      "À® 84160\n",
      "À© 83217\n",
      "…≤ 82881\n",
      "√∞ 76842\n",
      "Ãü 67262\n",
      "À¶ 66020\n",
      "·∫Ω 62046\n",
      " ê 61316\n",
      "…í 58223\n",
      "…π 56970\n",
      "Œ∏ 51376\n",
      "Ã© 48095\n",
      "√∏ 45332\n",
      "ƒ© 44738\n",
      "À• 44108\n",
      " à 41794\n",
      "…¶ 41516\n",
      "…£ 36789\n",
      "…Ø 36788\n",
      "‚ÅΩ 35285\n",
      "‚Åæ 35285\n",
      "·µù 34931\n",
      "Œ≤ 34388\n",
      "…§ 32685\n",
      "√µ 31560\n",
      "√£ 30361\n",
      "À£ 26879\n",
      " é 26520\n",
      " å 25398\n",
      "…µ 25132\n",
      "œá 24434\n",
      "À† 22455\n",
      " ë 21496\n",
      " ù 21244\n",
      "≈ì 19452\n",
      "…ª 19385\n",
      "√ß 16758\n",
      "c 15889\n",
      "Ã• 15660\n",
      "ÀÄ 14055\n",
      "~ 13113\n",
      " è 12944\n",
      " ∑ 12885\n",
      "‚Äø 12783\n",
      " â 12692\n",
      " º 12058\n",
      "Ãª 11544\n",
      "…• 11347\n",
      "- 10895\n",
      "≈© 10715\n",
      "Ãπ 10711\n",
      "…ó 10316\n",
      "…ì 10096\n",
      "…¥ 9899\n",
      "…ü 9763\n",
      "ÃÅ 9698\n",
      " ± 9533\n",
      "«é 9430\n",
      "Àë 8206\n",
      "√≠ 7882\n",
      "Õà 7799\n",
      "…≠ 7571\n",
      "√† 7253\n",
      "«í 7251\n",
      "q 6750\n",
      "√° 6684\n",
      "…ö 6672\n",
      "«ê 6656\n",
      "Ã∫ 6529\n",
      "ƒõ 6426\n",
      "Ãä 6349\n",
      "À§ 5531\n",
      "«Ω 5514\n",
      "ÃÄ 5095\n",
      "…ñ 4942\n",
      "Ãç 4758\n",
      "…∞ 4726\n",
      "√¢ 4178\n",
      "…≥ 4036\n",
      "…Ω 4014\n",
      "ƒß 3855\n",
      "…ú 3714\n",
      "√™ 3540\n",
      "…∏ 3532\n",
      "√∫ 3379\n",
      "«î 3199\n",
      "√¨ 3195\n",
      "√© 2972\n",
      "…± 2883\n",
      "…¨ 2802\n",
      "Ã¨ 2759\n",
      "√¥ 2690\n",
      "* 2670\n",
      "√Æ 2568\n",
      "√≥ 2409\n",
      " Ä 2246\n",
      " ï 2041\n",
      "…ù 2032\n",
      "√ª 1949\n",
      "√® 1854\n",
      "√≤ 1765\n",
      "ÃÑ 1654\n",
      "√Ø 1636\n",
      "…ò 1541\n",
      "Ã∞ 1476\n",
      "…Æ 1465\n",
      "√π 1371\n",
      "‚Üí 1309\n",
      "ƒÅ 1172\n",
      "·µä 1148\n",
      "À¢ 1055\n",
      "ÃÇ 760\n",
      "ÃÜ 749\n",
      "≈ç 739\n",
      "| 697\n",
      "·µë 694\n",
      "≈ô 660\n",
      "Ã§ 606\n",
      "‚Åø 588\n",
      "ƒ´ 579\n",
      "…¢ 550\n",
      "·µê 529\n",
      "¬† 515\n",
      "g 513\n",
      "Ãú 494\n",
      " ç 459\n",
      "ƒì 400\n",
      "Ãô 395\n",
      "…ß 352\n",
      "«É 333\n",
      "·µò 329\n",
      "À° 321\n",
      "·∏≠ 313\n",
      "·πµ 297\n",
      "Ãà 259\n",
      "≈´ 256\n",
      "…† 251\n",
      "·ππ 249\n",
      "»µ 240\n",
      "·∏ø 223\n",
      "«Ä 202\n",
      "Íúú 192\n",
      "…∂ 189\n",
      "…û 174\n",
      "Õú 148\n",
      "ÃΩ 141\n",
      "«Å 132\n",
      "‚àÖ 115\n",
      "·∏õ 110\n",
      "Ãå 85\n",
      "·π≥ 75\n",
      "‚Å∞ 63\n",
      "·ªπ 57\n",
      "·∫° 57\n",
      "·∂Ø 56\n",
      "·∂¢ 52\n",
      "‚Äâ 49\n",
      "Àï 45\n",
      "≈è 41\n",
      "·∑à 39\n",
      "Õâ 37\n",
      "Àû 35\n",
      "' 34\n",
      "> 30\n",
      "Àî 28\n",
      "√´ 28\n",
      "«£ 28\n",
      "·∏Å 27\n",
      "ƒÉ 26\n",
      "N 21\n",
      "·∂¨ 19\n",
      "·∂Æ 19\n",
      "‚Äñ 18\n",
      "Àó 17\n",
      "√º 16\n",
      "‚Ä¶ 16\n",
      "≈≠ 15\n",
      "Ãò 14\n",
      "ƒï 14\n",
      "‚óå 12\n",
      "Àñ 11\n",
      "C 11\n",
      "Ô∏é 10\n",
      "‚Üó 9\n",
      "‚Äå 8\n",
      "Õé 8\n",
      "·µè 8\n",
      "√∂ 7\n",
      " ô 7\n",
      "ƒ≠ 7\n",
      "√• 7\n",
      "ùÜë 7\n",
      " ¥ 6\n",
      "≈∑ 6\n",
      "‰∏Ä 6\n",
      "≈Ñ 6\n",
      "·¥ú 6\n",
      "‚Äã 5\n",
      "Q 5\n",
      "√Ω 5\n",
      "≈ï 4\n",
      "V 4\n",
      " ü 4\n",
      "·µà 4\n",
      "Ã£ 4\n",
      "Õç 4\n",
      "√± 4\n",
      " ≥ 4\n",
      "«π 4\n",
      "·Åä 3\n",
      "Õá 3\n",
      "‚Üò 3\n",
      "·∂£ 2\n",
      "·Ä¨ 2\n",
      "·Ä± 2\n",
      "·Ä∫ 2\n",
      "1 2\n",
      "‚Üì 2\n",
      " ò 2\n",
      "·µª 2\n",
      " Ñ 2\n",
      "·ª≥ 2\n",
      "Ãã 2\n",
      "·∫π 2\n",
      "≈à 2\n",
      " ú 1\n",
      "·µá 1\n",
      "·™Ω 1\n",
      "·Äõ 1\n",
      "·ÄÅ 1\n",
      "·Äª 1\n",
      "·ÄÑ 1\n",
      "; 1\n",
      "·Äò 1\n",
      "·Ä∏ 1\n",
      "+ 1\n",
      "‚Äô 1\n",
      "·Äô 1\n",
      "·Äï 1\n",
      "·ÄÄ 1\n",
      "‚Åì 1\n",
      "‚Åπ 1\n",
      "·∫ë 1\n",
      "& 1\n",
      "‰∏ç 1\n",
      " ¨ 1\n",
      " © 1\n",
      "êû™ 1\n",
      "·πΩ 1\n",
      "Íúî 1\n",
      "% 1\n",
      "·∑á 1\n",
      "…∫ 1\n",
      "·∑Ü 1\n",
      "»Å 1\n",
      "Õè 1\n",
      "√ø 1\n",
      "Àá 1\n",
      "·ªç 1\n",
      "·ªµ 1\n",
      "·µÑ 1\n",
      "«ø 1\n",
      ": 1\n"
     ]
    }
   ],
   "source": [
    "for x in symbols:\n",
    "    print(x, symbols_hist[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "Àà\n",
      "t\n",
      "a\n",
      "i\n",
      "s\n",
      "n\n",
      "k\n",
      "e\n",
      "o\n",
      "Àê\n",
      "l\n",
      "u\n",
      "m\n",
      "r\n",
      "p\n",
      " \n",
      "…ô\n",
      "d\n",
      "…™\n",
      " ≤\n",
      "…õ\n",
      "j\n",
      "Õ°\n",
      "…ë\n",
      "‚Åµ\n",
      "…î\n",
      "…ê\n",
      "ÃØ\n",
      "b\n",
      "¬≤\n",
      "…æ\n",
      "¬≥\n",
      "¬π\n",
      "v\n",
      "Àå\n",
      "Ãû\n",
      "Ã™\n",
      " Å\n",
      "…°\n",
      "z\n",
      "‚Å¥\n",
      "f\n",
      " É\n",
      " ä\n",
      "≈ã\n",
      "‚Åª\n",
      "ÃÉ\n",
      " ∞\n",
      "…®\n",
      "…ï\n",
      "Ã†\n",
      "w\n",
      "h\n",
      "Ãù\n",
      ")\n",
      "(\n",
      "√§\n",
      "y\n",
      " Ç\n",
      "Àß\n",
      " í\n",
      "√¶\n",
      "x\n",
      "…´\n",
      "Ãö\n",
      " î\n",
      " ã\n",
      "À®\n",
      "À©\n",
      "…≤\n",
      "√∞\n",
      "Ãü\n",
      "À¶\n",
      "·∫Ω\n",
      " ê\n",
      "…í\n",
      "…π\n",
      "Œ∏\n",
      "Ã©\n",
      "√∏\n",
      "ƒ©\n",
      "À•\n",
      " à\n",
      "…¶\n",
      "…£\n",
      "…Ø\n",
      "‚ÅΩ\n",
      "‚Åæ\n",
      "·µù\n",
      "Œ≤\n",
      "…§\n",
      "√µ\n",
      "√£\n",
      "À£\n",
      " é\n",
      " å\n",
      "…µ\n",
      "œá\n",
      "À†\n",
      " ë\n",
      " ù\n",
      "≈ì\n",
      "…ª\n",
      "√ß\n",
      "c\n",
      "Ã•\n",
      "ÀÄ\n",
      "~\n",
      " è\n",
      " ∑\n",
      "‚Äø\n",
      " â\n",
      " º\n",
      "Ãª\n",
      "…•\n",
      "-\n",
      "≈©\n",
      "Ãπ\n",
      "…ó\n",
      "…ì\n",
      "…¥\n",
      "…ü\n",
      "ÃÅ\n",
      " ±\n",
      "«é\n",
      "Àë\n",
      "√≠\n",
      "Õà\n",
      "…≠\n",
      "√†\n",
      "«í\n",
      "q\n",
      "√°\n",
      "…ö\n",
      "«ê\n",
      "Ã∫\n",
      "ƒõ\n",
      "Ãä\n",
      "À§\n",
      "«Ω\n",
      "ÃÄ\n",
      "…ñ\n",
      "Ãç\n",
      "…∞\n",
      "√¢\n",
      "…≥\n",
      "…Ω\n",
      "ƒß\n",
      "…ú\n",
      "√™\n",
      "…∏\n",
      "√∫\n",
      "«î\n",
      "√¨\n",
      "√©\n",
      "…±\n",
      "…¨\n",
      "Ã¨\n",
      "√¥\n",
      "*\n",
      "√Æ\n",
      "√≥\n",
      " Ä\n",
      " ï\n",
      "…ù\n",
      "√ª\n",
      "√®\n",
      "√≤\n",
      "ÃÑ\n",
      "√Ø\n",
      "…ò\n",
      "Ã∞\n",
      "…Æ\n",
      "√π\n",
      "‚Üí\n",
      "ƒÅ\n",
      "·µä\n",
      "À¢\n",
      "ÃÇ\n",
      "ÃÜ\n",
      "≈ç\n",
      "|\n",
      "·µë\n",
      "≈ô\n",
      "Ã§\n",
      "‚Åø\n",
      "ƒ´\n",
      "…¢\n",
      "·µê\n",
      "¬†\n",
      "g\n",
      "Ãú\n",
      " ç\n",
      "ƒì\n",
      "Ãô\n",
      "…ß\n",
      "«É\n",
      "·µò\n",
      "À°\n",
      "·∏≠\n",
      "·πµ\n",
      "Ãà\n",
      "≈´\n",
      "…†\n",
      "·ππ\n",
      "»µ\n",
      "·∏ø\n",
      "«Ä\n",
      "Íúú\n",
      "…∂\n",
      "…û\n",
      "Õú\n",
      "ÃΩ\n",
      "«Å\n",
      "‚àÖ\n",
      "·∏õ\n",
      "Ãå\n",
      "·π≥\n",
      "‚Å∞\n",
      "·ªπ\n",
      "·∫°\n",
      "·∂Ø\n",
      "·∂¢\n",
      "‚Äâ\n",
      "Àï\n",
      "≈è\n",
      "·∑à\n",
      "Õâ\n",
      "Àû\n",
      "'\n",
      ">\n",
      "Àî\n",
      "√´\n",
      "«£\n",
      "·∏Å\n",
      "ƒÉ\n",
      "N\n",
      "·∂¨\n",
      "·∂Æ\n",
      "‚Äñ\n",
      "Àó\n",
      "√º\n",
      "‚Ä¶\n",
      "≈≠\n",
      "Ãò\n",
      "ƒï\n",
      "‚óå\n",
      "Àñ\n",
      "C\n",
      "Ô∏é\n",
      "‚Üó\n",
      "‚Äå\n",
      "Õé\n",
      "·µè\n",
      "√∂\n",
      " ô\n",
      "ƒ≠\n",
      "√•\n",
      "ùÜë\n",
      " ¥\n",
      "≈∑\n",
      "‰∏Ä\n",
      "≈Ñ\n",
      "·¥ú\n",
      "‚Äã\n",
      "Q\n",
      "√Ω\n",
      "≈ï\n",
      "V\n",
      " ü\n",
      "·µà\n",
      "Ã£\n",
      "Õç\n",
      "√±\n",
      " ≥\n",
      "«π\n",
      "·Åä\n",
      "Õá\n",
      "‚Üò\n",
      "·∂£\n",
      "·Ä¨\n",
      "·Ä±\n",
      "·Ä∫\n",
      "1\n",
      "‚Üì\n",
      " ò\n",
      "·µª\n",
      " Ñ\n",
      "·ª≥\n",
      "Ãã\n",
      "·∫π\n",
      "≈à\n",
      " ú\n",
      "·µá\n",
      "·™Ω\n",
      "·Äõ\n",
      "·ÄÅ\n",
      "·Äª\n",
      "·ÄÑ\n",
      ";\n",
      "·Äò\n",
      "·Ä∏\n",
      "+\n",
      "‚Äô\n",
      "·Äô\n",
      "·Äï\n",
      "·ÄÄ\n",
      "‚Åì\n",
      "‚Åπ\n",
      "·∫ë\n",
      "&\n",
      "‰∏ç\n",
      " ¨\n",
      " ©\n",
      "êû™\n",
      "·πΩ\n",
      "Íúî\n",
      "%\n",
      "·∑á\n",
      "…∫\n",
      "·∑Ü\n",
      "»Å\n",
      "Õè\n",
      "√ø\n",
      "Àá\n",
      "·ªç\n",
      "·ªµ\n",
      "·µÑ\n",
      "«ø\n",
      ":\n"
     ]
    }
   ],
   "source": [
    "for s in symbols:\n",
    "    if s == \"/\" or s == \"[\" or s == \"]\":\n",
    "        continue \n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from languages import LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pronunciation</th>\n",
       "      <th>word</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/ ê/</td>\n",
       "      <td>∆∂</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/aapa/</td>\n",
       "      <td>–∞–∞–±–∞</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[ î√§ÀëÀàb…ú]</td>\n",
       "      <td>–∞–∞–±–∞</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[ƒÅb Å ≤a]</td>\n",
       "      <td>–∞–∞–±”∑—å–∞</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[aÀêdzara]</td>\n",
       "      <td>–∞–∞”°–∞—Ä–∞</td>\n",
       "      <td>Abkhaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 pronunciation    word language\n",
       "0           0           / ê/       ∆∂   Abkhaz\n",
       "1           1        /aapa/    –∞–∞–±–∞   Abkhaz\n",
       "2           2      [ î√§ÀëÀàb…ú]    –∞–∞–±–∞   Abkhaz\n",
       "3           3       [ƒÅb Å ≤a]  –∞–∞–±”∑—å–∞   Abkhaz\n",
       "4           4     [aÀêdzara]  –∞–∞”°–∞—Ä–∞   Abkhaz"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_df = pd.read_csv(\"full_dataset_v0.csv\")\n",
    "symbols = np.load(\"symbols.npy\")\n",
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer(PreTrainedTokenizer):\n",
    "    def __init__(self, symbol_list):\n",
    "        super().__init__(max_len=512)  # You can adjust max_len based on your needs\n",
    "        self.vocabulary = {\n",
    "            \"[PAD]\": 0,\n",
    "            \"[CLS]\": 1,\n",
    "            \"[SEP]\": 2,\n",
    "            \"[MASK]\": 3,\n",
    "            \"[UNK]\": 4,\n",
    "        }\n",
    "        for symbol in symbol_list:\n",
    "            self.vocabulary[symbol] = len(self.vocabulary)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        tokens = []\n",
    "        for char in text:\n",
    "            tokens.append(char)\n",
    "        return tokens\n",
    "    \n",
    "    def convert_tokens_to_ids(self, x):\n",
    "        tokens = self._tokenize(x)\n",
    "        return [self._convert_token_to_id(token) for token in tokens]\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        return self.vocabulary.get(token, self.vocabulary[\"[UNK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = LANGUAGES\n",
    "\n",
    "    def tokenize(self, x):\n",
    "        return self.vocabulary.index(x) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciation_tokenizer = CustomTokenizer(symbols)\n",
    "language_tokenizer = LanguageTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5, 83, 5], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(loaded_df)):\n",
    "    x = loaded_df.iloc[i]\n",
    "    pronunciations = pronunciation_tokenizer(x[\"pronunciation\"])\n",
    "    languages = language_tokenizer.tokenize(x[\"language\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
